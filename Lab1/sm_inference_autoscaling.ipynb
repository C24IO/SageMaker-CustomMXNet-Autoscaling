{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoscale SageMaker endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook, we will discover 3 distinct ways to scale SageMaker Endpoints. \n",
    "\n",
    "![Auto Scaling Groups](as-basic-diagram.png)\n",
    "\n",
    "#### 1.\tAutoscale using Auto Scaling Groups and Simple Scaling\n",
    "#### 2.\tAutoscale using Auto Scaling Groups and Step Scaling \n",
    "#### 3.\tAutoscale on demand, without defining a trigger a priori â€“ using `update_endpoint_weights_and_capacities` API call\n",
    "\n",
    "![Update API](update_api.png)\n",
    "\n",
    "With ```step scaling and simple scaling```, you choose scaling metrics and threshold values for the CloudWatch alarms that trigger the scaling process. You also define how your Auto Scaling group should be scaled when a threshold is in breach for a specified number of evaluation periods. We strongly recommend that you use a target tracking scaling policy to scale on a metric like average CPU utilization or the SageMakerVariantInvocationsPerInstance metric. \n",
    "\n",
    "Metrics that decrease when capacity increases and increase when capacity decreases can be used to proportionally scale out or in the number of instances using target tracking. \n",
    "\n",
    "![SageMaker AutoScaling](SM-AS.png)\n",
    "\n",
    "You still have the option to use ```step scaling as an additional policy for a more advanced configuration```. For example, you can configure a more aggressive response when demand reaches a certain level.\n",
    "\n",
    "Step scaling policies and simple scaling policies are two of the dynamic scaling options available for you to use. The main difference between the policy types is the step adjustments that you get with step scaling policies. When step adjustments are applied, and they increase or decrease the current capacity of your Auto Scaling group, the adjustments vary based on the size of the alarm breach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import boto3\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=4)\n",
    "role = get_execution_role()\n",
    "sagemaker_client = boto3.Session().client(service_name='sagemaker')\n",
    "\n",
    "# Copy over the endpoint name from our other notebook\n",
    "\n",
    "endpoint_name = 'chazarey-mxnet-serving-160-gpu-py2-2020-06-11-04-39-32-640'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker_client.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "pp.pprint(response) # We are interested in 'EndpointStatus', CurrentInstanceCount' & 'DesiredInstanceCount' same can be observed from the console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a scaling policy to autoscale based on number of times per minute that each instance is invoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('application-autoscaling') # Common class representing Application Auto Scaling for SageMaker amongst other services\n",
    "\n",
    "resource_id='endpoint/' + endpoint_name + '/variant/' + 'AllTraffic' # This is the format in which application autoscaling references the endpoint\n",
    "\n",
    "response = client.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker', #\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=2\n",
    ")\n",
    "\n",
    "response = client.put_scaling_policy(\n",
    "    PolicyName='Invocations-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker', # The namespace of the AWS service that provides the resource. \n",
    "    ResourceId=resource_id, # Endpoint name \n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount', # SageMaker supports only Instance Count\n",
    "    PolicyType='TargetTrackingScaling', # 'StepScaling'|'TargetTrackingScaling'\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 10.0, # The target value for the metric. - here the metric is - SageMakerVariantInvocationsPerInstance\n",
    "        'PredefinedMetricSpecification': {\n",
    "            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance', # is the average number of times per minute that each instance for a variant is invoked. \n",
    "        },\n",
    "        'ScaleInCooldown': 600, # The cooldown period helps you prevent your Auto Scaling group from launching or terminating \n",
    "                                # additional instances before the effects of previous activities are visible. \n",
    "                                # You can configure the length of time based on your instance startup time or other application needs.\n",
    "                                # ScaleInCooldown - The amount of time, in seconds, after a scale in activity completes before another scale in activity can start. \n",
    "        'ScaleOutCooldown': 300 # ScaleOutCooldown - The amount of time, in seconds, after a scale out activity completes before another scale out activity can start.\n",
    "        \n",
    "        # 'DisableScaleIn': True|False - ndicates whether scale in by the target tracking policy is disabled. \n",
    "                            # If the value is true , scale in is disabled and the target tracking policy won't remove capacity from the scalable resource.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait till endpoint state is 'Updating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#We need to wait untill the state transitions from 'Updating' to apply another scaling operation\n",
    "\n",
    "response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Updating':\n",
    "    time.sleep(1)\n",
    "    response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a scaling policy based on CPUUtilization metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.put_scaling_policy(\n",
    "    PolicyName='CPUUtil-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 90.0,\n",
    "        'CustomizedMetricSpecification':\n",
    "        {\n",
    "            'MetricName': 'CPUUtilization',\n",
    "            'Namespace': '/aws/sagemaker/Endpoints',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name },\n",
    "                {'Name': 'VariantName','Value': 'AllTraffic'}\n",
    "            ],\n",
    "            'Statistic': 'Average', # Possible - 'Statistic': 'Average'|'Minimum'|'Maximum'|'SampleCount'|'Sum'\n",
    "            'Unit': 'Percent'\n",
    "        },\n",
    "        'ScaleInCooldown': 600,\n",
    "        'ScaleOutCooldown': 300\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait till endpoint state is 'Updating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Updating':\n",
    "    time.sleep(1)\n",
    "    response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a step scaling policy based on OverheadLatency metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.put_scaling_policy(\n",
    "    PolicyName='OverheadLatency-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='StepScaling', \n",
    "    StepScalingPolicyConfiguration={\n",
    "        'AdjustmentType': 'ChangeInCapacity', # 'PercentChangeInCapacity'|'ExactCapacity' Specifies whether the ScalingAdjustment value in a StepAdjustment \n",
    "                                              # is an absolute number or a percentage of the current capacity.\n",
    "        'StepAdjustments': [ # A set of adjustments that enable you to scale based on the size of the alarm breach.\n",
    "            {\n",
    "                'MetricIntervalLowerBound': 0.0, # The lower bound for the difference between the alarm threshold and the CloudWatch metric.\n",
    "                 # 'MetricIntervalUpperBound': 100.0, # The upper bound for the difference between the alarm threshold and the CloudWatch metric.\n",
    "                'ScalingAdjustment': 1 # The amount by which to scale, based on the specified adjustment type. \n",
    "                                       # A positive value adds to the current capacity while a negative number removes from the current capacity.\n",
    "            },\n",
    "        ],\n",
    "        # 'MinAdjustmentMagnitude': 1, # The minimum number of instances to scale. - only for 'PercentChangeInCapacity'\n",
    "        'Cooldown': 120,\n",
    "        'MetricAggregationType': 'Average', # 'Minimum'|'Maximum'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example - scaling using a diffrent amount at each step - \n",
    "\n",
    "```yaml\n",
    "{\n",
    "  \"AdjustmentType\": \"ChangeInCapacity\",\n",
    "  \"MetricAggregationType\": \"Average\",\n",
    "  \"Cooldown\": 60,\n",
    "  \"StepAdjustments\": [ \n",
    "    {\n",
    "      \"MetricIntervalLowerBound\": 0,\n",
    "      \"MetricIntervalUpperBound\": 15,\n",
    "      \"ScalingAdjustment\": 1\n",
    "    },\n",
    "    {\n",
    "      \"MetricIntervalLowerBound\": 15,\n",
    "      \"MetricIntervalUpperBound\": 25,\n",
    "      \"ScalingAdjustment\": 2\n",
    "    },\n",
    "    {\n",
    "      \"MetricIntervalLowerBound\": 25,\n",
    "      \"ScalingAdjustment\": 3\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait till endpoint state is 'Updating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Updating':\n",
    "    time.sleep(1)\n",
    "    response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the scaling policies attached to this target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.describe_scaling_policies(\n",
    "    ServiceNamespace='sagemaker'\n",
    ")\n",
    "\n",
    "for i in response['ScalingPolicies']:\n",
    "    print('')\n",
    "    pp.pprint(i['PolicyName'])\n",
    "    print('')\n",
    "    if('TargetTrackingScalingPolicyConfiguration' in i):\n",
    "        pp.pprint(i['TargetTrackingScalingPolicyConfiguration']) the\n",
    "    else:\n",
    "        pp.pprint(i['StepScalingPolicyConfiguration'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale without defining a policy - use - ```update_endpoint_weights_and_capacities```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see if we have the endpoint available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Updating':\n",
    "    time.sleep(1)\n",
    "    response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker_client.update_endpoint_weights_and_capacities(\n",
    "    EndpointName=endpoint_name,\n",
    "    DesiredWeightsAndCapacities=[\n",
    "        {\n",
    "            'VariantName': 'AllTraffic',\n",
    "            'DesiredInstanceCount': 5\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "response = sagemaker_client.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "pp.pprint(response) # We are interested in 'EndpointStatus', CurrentInstanceCount' & 'DesiredInstanceCount' same can be observed from the console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait till endpoint state is 'Updating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Updating':\n",
    "    time.sleep(1)\n",
    "    response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do it again, but scale down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker_client.update_endpoint_weights_and_capacities(\n",
    "    EndpointName=endpoint_name,\n",
    "    DesiredWeightsAndCapacities=[\n",
    "        {\n",
    "            'VariantName': 'AllTraffic',\n",
    "            'DesiredInstanceCount': 1\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "response = sagemaker_client.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug - List the scaling activties performed till now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides descriptive information about the scaling activities in the specified namespace from the previous six weeks.\n",
    "\n",
    "response = client.describe_scaling_activities(\n",
    "    ServiceNamespace='sagemaker'\n",
    ")\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all the policies attached to this target\n",
    "\n",
    "# You can delete a scaling policy with the AWS Management Console, \n",
    "# the AWS CLI, or the Application Auto Scaling API. You must delete a scaling policy if you wish to update a model's endpoint.\n",
    "\n",
    "response = client.describe_scaling_policies(\n",
    "    ServiceNamespace='sagemaker'\n",
    ")\n",
    "\n",
    "for i in response['ScalingPolicies']:\n",
    "    print('')\n",
    "    pp.pprint(i['PolicyName'])\n",
    "    print('')\n",
    "    #pp.pprint(i['TargetTrackingScalingPolicyConfiguration']) or pp.pprint(i['StepScalingPolicyConfiguration'])\n",
    "    print('')\n",
    "    response = client.delete_scaling_policy(\n",
    "        PolicyName=i['PolicyName'],\n",
    "        ServiceNamespace='sagemaker',\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension='sagemaker:variant:DesiredInstanceCount'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deregister scalable target\n",
    "\n",
    "response = client.deregister_scalable_target(\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "* How to define a autoscaling policy - https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-auto-scaling-add-code-define.html\n",
    "* How to load test to derive a scaling strategy - https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-scaling-loadtest.html\n",
    "* API references: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/application-autoscaling.html\n",
    "* SageMaker CloudWatch Metrics Definitions - https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html\n",
    "* Customized metric specification - https://docs.aws.amazon.com/autoscaling/application/APIReference/API_CustomizedMetricSpecification.html\n",
    "* Publishing custom metrics - https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
